{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covid-19 Data Aggregation\n",
    "\n",
    "This notebook is in conjunction with the ongoing research on Covid-19 and human mobility and serves the purpose of preprocessing Covid-19 data by taking the input data of cumulative covid-19 data at county level from New York Times to Metropolitan Statistical Area (MSA) level for further study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Outline\n",
    "- cumulative to daily\n",
    "- transpose\n",
    "- aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "import json\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the parameters below to specify a beginning and an ending date \n",
    "beginDate = dt.datetime(2020, 2, 14)\n",
    "endDate = dt.datetime(2021, 2, 7)\n",
    "inputCovid = './data/Covid-19 cumulative.csv'\n",
    "inputMetro = './data/metro_county.csv'\n",
    "\n",
    "# change the parameters below to specify an interval (for example interval = 1\n",
    "# means daily cases and interval = 7 means weekly cases)\n",
    "interval = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>county</th>\n",
       "      <th>state</th>\n",
       "      <th>fips</th>\n",
       "      <th>cases</th>\n",
       "      <th>deaths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>3/19/2020</td>\n",
       "      <td>Abbeville</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>45001.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5873</th>\n",
       "      <td>3/20/2020</td>\n",
       "      <td>Abbeville</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>45001.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6877</th>\n",
       "      <td>3/21/2020</td>\n",
       "      <td>Abbeville</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>45001.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>3/22/2020</td>\n",
       "      <td>Abbeville</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>45001.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9208</th>\n",
       "      <td>3/23/2020</td>\n",
       "      <td>Abbeville</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>45001.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date     county           state     fips  cases  deaths\n",
       "5000  3/19/2020  Abbeville  South Carolina  45001.0      1     0.0\n",
       "5873  3/20/2020  Abbeville  South Carolina  45001.0      1     0.0\n",
       "6877  3/21/2020  Abbeville  South Carolina  45001.0      1     0.0\n",
       "7997  3/22/2020  Abbeville  South Carolina  45001.0      1     0.0\n",
       "9208  3/23/2020  Abbeville  South Carolina  45001.0      1     0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input cumulative data\n",
    "data = pd.read_csv(inputCovid)\n",
    "data = data.sort_values(by = ['county', 'state'])\n",
    "copy = data\n",
    "data.to_csv(\"./data/daily count.csv\", index = False)\n",
    "data = pd.read_csv(\"./data/daily count.csv\")\n",
    "copy.to_csv(\"./data/daily count_copy.csv\", index = False)\n",
    "copy = pd.read_csv(\"./data/daily count_copy.csv\")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# input MSA to county reference table\n",
    "metro = pd.read_csv(inputMetro)\n",
    "metro_initial = metro\n",
    "metro.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input US state abbreviations reference table\n",
    "state_abbr = pd.read_csv('./data/us states abbreviations.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cumulative to daily\n",
    "This section is for converting cumulative cases to daily cases. The basic idea is that the daily case for a specific day is the cumulative cases on the day minus the cumulative cases on the day before it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "data['fips'] = data['fips'].fillna(-1)\n",
    "while i < len(data.index):\n",
    "    if data.at[i, 'county'] == data.at[i - 1, 'county'] and data.at[i, 'state'] == data.at[i - 1, 'state']:\n",
    "        if (data.at[i, 'cases'] < copy.at[i - 1, 'cases']):\n",
    "            data.at[i, 'cases'] = copy.at[i - 1, 'cases']\n",
    "        if (data.at[i, 'deaths'] < copy.at[i - 1, 'deaths']):\n",
    "            data.at[i, 'deaths'] = copy.at[i - 1, 'deaths']\n",
    "        data.at[i, 'cases'] = data.at[i, 'cases'] - copy.at[i - 1, 'cases']\n",
    "        data.at[i, 'deaths'] = data.at[i, 'deaths'] - copy.at[i - 1, 'deaths']\n",
    "    i += 1\n",
    "data = data.astype({'fips': int})\n",
    "data[\"date\"] = pd.to_datetime(data[\"date\"])\n",
    "data = data.sort_values(by = ['date'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### aggregate\n",
    "This section is for aggregating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the metro reference table with state reference table\n",
    "metro = metro.merge(state_abbr, how ='inner', \n",
    "                     left_on = 'states_msa', \n",
    "                     right_on = 'Abbreviation')\n",
    "metro['states_msa'] = metro['State']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge again with the covid data\n",
    "merged = metro.merge(covid, how='inner', \n",
    "                     left_on=[\"states_msa\", \"name10_county\"], \n",
    "                     right_on=[\"state\",\"county\"])\n",
    "merged = merged[['date', 'county', 'cases', \n",
    "                 'deaths', 'name_msa', 'states_msa_code', 'states_msa', 'states_msa_full',\n",
    "                 'geoid_msa']]  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out any rows with dates not in the range\n",
    "merged[\"date\"] = pd.to_datetime(merged[\"date\"])\n",
    "merged = merged[merged.date <= enddate]\n",
    "merged = merged[merged.date >= startdate]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "iterate_start = startdate\n",
    "\n",
    "interval_data = merged\n",
    "output = pd.DataFrame()\n",
    "\n",
    "while iterate_start <= enddate:\n",
    "    iterate_end = iterate_start + timedelta(days = interval)\n",
    "\n",
    "    eachInterval = interval_data[interval_data.date >= iterate_start]\n",
    "    eachInterval = eachInterval[eachInterval.date < iterate_end]\n",
    "\n",
    "\n",
    "    eachInterval = eachInterval.groupby(['name_msa'])['cases', 'deaths'].sum()\n",
    "    eachInterval = eachInterval.merge(metro_initial, left_on='name_msa', right_on='name_msa')[['states_msa_code', 'states_msa', \n",
    "                                'states_msa_full', \"geoid_msa\",\n",
    "                               'name_msa', 'cases', 'deaths']].sort_values(by = 'states_msa_code')\n",
    "    eachInterval['interval_start'] = iterate_start\n",
    "    eachInterval = eachInterval.drop_duplicates(subset=['name_msa'])\n",
    "\n",
    "    output = output.append(eachInterval)\n",
    "    iterate_start = iterate_start + timedelta(days=interval)\n",
    "\n",
    "\n",
    "output.to_csv(\"./data/output.csv\", index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "This function is for transposing the output.csv file to output the data with each\n",
    "date being a column\n",
    "\n",
    "Args:\n",
    "    input_covid: the output from aggregate function in csv format\n",
    "                \n",
    "Returns:\n",
    "    the reformatted cases and deaths data at MSA level in the US\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "def transform_MSA(input_covid):\n",
    "    input_df = pd.read_csv(input_covid)\n",
    "    geoid_msa = {}\n",
    "    MSA_all_cases = {}\n",
    "    MSA_all_deaths = {}\n",
    "    all_dates = {}\n",
    "\n",
    "    for index, row in input_df.iterrows():\n",
    "        MSA_all_cases[row['name_msa']] = []\n",
    "        MSA_all_deaths[row['name_msa']] = []\n",
    "        all_dates[row['interval_start']] = 0\n",
    "        geoid_msa[row['geoid_msa']] = 0\n",
    "    \n",
    "    for index, row in input_df.iterrows():\n",
    "        MSA_all_cases[row['name_msa']].append(row['cases'])\n",
    "        MSA_all_deaths[row['name_msa']].append(row['deaths'])\n",
    "    \n",
    "    MSA_all_cases_list = []\n",
    "    for value in MSA_all_cases.values():\n",
    "        MSA_all_cases_list.append(value)\n",
    "        \n",
    "    MSA_all_deaths_list = []\n",
    "    for value in MSA_all_deaths.values():\n",
    "        for index, v in enumerate(value):\n",
    "            value[index] = int(v)\n",
    "        #print(value)\n",
    "        MSA_all_deaths_list.append(value)\n",
    "    \n",
    "    for i in MSA_all_cases_list:\n",
    "        if (len(i) < len(all_dates)):\n",
    "            diff = len(all_dates) - len(i)\n",
    "            for j in range(diff):\n",
    "                i.insert(j, 0)\n",
    "                \n",
    "    for i in MSA_all_deaths_list:\n",
    "        if (len(i) < len(all_dates)):\n",
    "            diff = len(all_dates) - len(i)\n",
    "            for j in range(diff):\n",
    "                i.insert(j, 0)\n",
    "\n",
    "    dates = list(all_dates.keys())\n",
    "    \n",
    "\n",
    "    \n",
    "    output_cases = pd.DataFrame(MSA_all_cases_list, columns = dates)\n",
    "    output_cases.insert(0, 'geoid', list(geoid_msa.keys()))\n",
    "    output_cases.insert(1, 'name', list(MSA_all_cases.keys()))\n",
    "     \n",
    "    output_deaths = pd.DataFrame(MSA_all_deaths_list, columns = dates)\n",
    "    output_deaths.insert(0, 'geoid', list(geoid_msa.keys()))\n",
    "    output_deaths.insert(1, 'name', list(MSA_all_deaths.keys()))\n",
    "    \n",
    "\n",
    "#     output_deaths = output_deaths.astype(float)\n",
    "#     output_deaths = output_deaths.astype(int)\n",
    "#     for index, row in output_deaths.iterrows():\n",
    "#         print(row) \n",
    "    \n",
    "    \n",
    "    output_cases.to_csv(\"./data/output_cases.csv\", index = False)\n",
    "    output_deaths.to_csv(\"./data/output_deaths.csv\", index = False)\n",
    "    \n",
    "    return output_cases, output_deaths\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "This function is for transposing the global covid-19 data to output the data\n",
    "with each date being a column\n",
    "\n",
    "Args:\n",
    "    input_covid: global covid-19 data in ./data/covid_world.csv\n",
    "                \n",
    "Returns:\n",
    "    the reformatted cases and deaths data at country level\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def transform_world(input_world, begindate, enddate):\n",
    "    df = pd.read_csv(input_world)\n",
    "    \n",
    "    geoid = pd.read_csv('./data/geoid.csv')\n",
    "    df = df.merge(geoid, how='inner', \n",
    "                         left_on=['location'], \n",
    "                         right_on=['Location (Short Name)'] )\n",
    "    \n",
    "    df = df[['Geographical location identifier (decimal)', 'iso_code', 'date', 'continent', 'location', \n",
    "             'new_cases', 'new_deaths']]\n",
    "    \n",
    "    iso_country = {}\n",
    "    country_all_cases = {}\n",
    "    country_all_deaths = {}\n",
    "    all_dates = {}\n",
    "    continent = {}\n",
    "    locations = {}\n",
    "    geoid = {}\n",
    "\n",
    "    for i in range(df.shape[0]):\n",
    "        transform = df.at[i, 'date']\n",
    "        transform = transform.split('/')\n",
    "        transform = transform[0] + '-' + transform[1] + '-' + transform[2]\n",
    "        #print(transform)\n",
    "    \n",
    "    df['date'] = pd.to_datetime(df[\"date\"])\n",
    "    \n",
    "    for i in range(df.shape[0]):\n",
    "        if (df.at[i, 'date'] < begindate or df.at[i, 'date'] > enddate):\n",
    "            df = df.drop([i])\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        country_all_cases[row['iso_code']] = []\n",
    "        country_all_deaths[row['iso_code']] = []\n",
    "        all_dates[row['date']] = 0\n",
    "        iso_country[row['iso_code']] = 0\n",
    "        \n",
    "        continent[row['continent']] = 0\n",
    "        locations[row['location']] = 0\n",
    "        geoid[row['Geographical location identifier (decimal)']] = 0\n",
    "        \n",
    "    for index, row in df.iterrows():\n",
    "        country_all_cases[row['iso_code']].append(row['new_cases'])\n",
    "        country_all_deaths[row['iso_code']].append(row['new_deaths'])\n",
    "    \n",
    "    country_all_cases_list = []\n",
    "    for value in country_all_cases.values():\n",
    "        country_all_cases_list.append(value)\n",
    "        \n",
    "    country_all_deaths_list = []\n",
    "    for value in country_all_deaths.values():\n",
    "        country_all_deaths_list.append(value)\n",
    "    \n",
    "\n",
    "    dates = list(all_dates.keys())\n",
    "    \n",
    "\n",
    "    \n",
    "    output_cases = pd.DataFrame(country_all_cases_list, columns = dates)\n",
    "    output_cases.insert(0, 'geoid', list(geoid.keys()))\n",
    "    output_cases.insert(1, 'name', list(locations.keys()))\n",
    "    \n",
    "       \n",
    "    output_deaths = pd.DataFrame(country_all_deaths_list, columns = dates)\n",
    "    output_deaths.insert(0, 'geoid', list(geoid.keys()))\n",
    "    output_deaths.insert(1, 'name', list(locations.keys()))\n",
    "    \n",
    "\n",
    "    return output_cases, output_deaths\n",
    "    \n",
    "    #output_cases.to_csv(\"./data/output_cases_world.csv\", index = False)\n",
    "    #output_deaths.to_csv(\"./data/output_deaths_world.csv\", index = False)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "This function is for merging the MSA level data in the US with the country level data by calling both the transform function\n",
    "for the MSA level data and for the country level data\n",
    "\n",
    "Args:\n",
    "    begindate:\n",
    "    enddate:\n",
    "                \n",
    "Returns:\n",
    "    None. The output will be written to './data/output_cases.csv' and './data/output_deaths.csv'\n",
    "\n",
    "\"\"\"\n",
    "def merge(begindate, enddate):\n",
    "    output_cases_MSA, output_deaths_MSA = transform_MSA('./data/output.csv')\n",
    "    output_cases_world, output_deaths_world = transform_world('./data/covid_world.csv', begindate, enddate)\n",
    "    \n",
    "    for i in range(output_cases_world.shape[0]):\n",
    "        output_cases_MSA.loc[output_cases_MSA.shape[0] + i] = list(output_cases_world.loc[i])\n",
    "    \n",
    "    for i in range(output_deaths_world.shape[0]):\n",
    "        output_deaths_MSA.loc[output_deaths_MSA.shape[0] + i] = list(output_deaths_world.loc[i])\n",
    "    \n",
    "    output_cases_MSA.to_csv(\"./data/output_cases.csv\", index = False)\n",
    "    output_deaths_MSA.to_csv(\"./data/output_deaths.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "This function is for converting the output in csv format to js format \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def convert_to_js(param):\n",
    "\n",
    "    disease = param['Disease']\n",
    "    beginDate = param['begin_date']\n",
    "    endDate = param['end_date']\n",
    "    shapefile = param['shapefile']\n",
    "    \n",
    "    with open(shapefile, errors='replace') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    beginDate = str_to_date(beginDate)\n",
    "    endDate = str_to_date(endDate)\n",
    "    \n",
    "    \n",
    "    \n",
    "    df = pd.read_csv(disease)\n",
    "    \n",
    "    \n",
    " \n",
    "    columns = list(df.columns)\n",
    "    columns.pop(0)\n",
    "    columns.pop(0)\n",
    "    \n",
    "    for column in columns:\n",
    "        column_date = str_to_date(column)\n",
    "        if (column_date > endDate or column_date < beginDate):\n",
    "            df = df.drop(column, 1)\n",
    "            \n",
    "    \n",
    "    heading = list(df.columns)\n",
    "    ofile = open('./data/test.js', 'w')\n",
    "    ofile.write('var GEO_VARIABLES =\\n')\n",
    "    ofile.write('[\\n')\n",
    "    ofile.write('  '+json.dumps(heading)+',\\n')\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        values = list(row)\n",
    "        ofile.write('  '+json.dumps(values)+',\\n')\n",
    "    \n",
    "    \n",
    "    ofile.write(']\\n')\n",
    "    ofile.close()\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Helper function for converting string to datetime, string must be in the formate of \"month-date-year\", e.g. \"2-14-2020\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def str_to_date(input_string):\n",
    "    input_string = input_string.split('-')\n",
    "    \n",
    "    \n",
    "    for index in range(len(input_string)):\n",
    "        input_string[index] = int(input_string[index])\n",
    "\n",
    "    input_string = dt.datetime(input_string[0], input_string[1], input_string[2])\n",
    "    \n",
    "    return input_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    \n",
    "#     dailyCount = cumulativeToDaily(inputFile)\n",
    "#     dailyCount.to_csv(\"./data/daily count.csv\", index = False)\n",
    "    \n",
    "    #inputCovid = pd.read_csv('./data/daily count.csv')\n",
    "    \n",
    "    \n",
    "    #aggregate(inputCovid, inputMetro, beginDate, endDate, interval)\n",
    "    \n",
    "    transform_MSA('./data/output.csv')\n",
    "    \n",
    "#     merge(beginDate, endDate)\n",
    "    \n",
    "#     param = {\n",
    "#         'Disease': './data/output_deaths.csv',  \n",
    "#         'begin_date': \"2020-02-22\",\n",
    "#         'end_date': \"2020-06-10\",\n",
    "#         'shapefile': \"./shp/world_region.shp\",\n",
    "#     }\n",
    "    \n",
    "#     convert_to_js(param)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
