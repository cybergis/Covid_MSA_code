{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "This function is for converting cumulative count to daily count and write to the data folder\n",
    "\n",
    "Args:\n",
    "    inputFile: the cumulative count at county level collected from New York Times\n",
    "                the path for it is at './data/Covid-19 cumulative.csv'\n",
    "                \n",
    "Returns:\n",
    "    the daily count in dataframe format\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def cumulativeToDaily(inputFile):\n",
    "    data = pd.read_csv(inputFile)\n",
    "    copy = pd.read_csv(inputFile)\n",
    "    data = data.sort_values(by=['county', 'state'])\n",
    "    copy = copy.sort_values(by=['county', 'state'])\n",
    "    data.to_csv(\"./data/daily count.csv\", index = False)\n",
    "    data = pd.read_csv(\"./data/daily count.csv\")\n",
    "    copy.to_csv(\"./data/daily count_copy.csv\", index = False)\n",
    "    copy = pd.read_csv(\"./data/daily count_copy.csv\")\n",
    "    i = 1\n",
    "    data['fips'] = data['fips'].fillna(-1)\n",
    "    #print(data[data['county'] == \"Cook\"])\n",
    "    while i < len(data.index):\n",
    "        if data.at[i, 'county'] == data.at[i - 1, 'county'] and data.at[i, 'state'] == data.at[i - 1, 'state']:\n",
    "            #print(data.at[i, 'county'], data.at[i - 1, 'county'])\n",
    "            if (data.at[i, 'cases'] < copy.at[i - 1, 'cases']):\n",
    "                data.at[i, 'cases'] = copy.at[i - 1, 'cases']\n",
    "            if (data.at[i, 'deaths'] < copy.at[i - 1, 'deaths']):\n",
    "                data.at[i, 'deaths'] = copy.at[i - 1, 'deaths']\n",
    "            data.at[i, 'cases'] = data.at[i, 'cases'] - copy.at[i - 1, 'cases']\n",
    "            data.at[i, 'deaths'] = data.at[i, 'deaths'] - copy.at[i - 1, 'deaths']\n",
    "        i += 1\n",
    "    data = data.astype({'fips': int})\n",
    "    data[\"date\"] = pd.to_datetime(data[\"date\"])\n",
    "    data = data.sort_values(by = ['date'])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "This function is for aggregating Covid-19 count from county level to MSA level\n",
    "\n",
    "Args:\n",
    "    covid: the daily count in csv format\n",
    "    metro: a reference table in csv format for showing all the MSAs and the counties included in them\n",
    "    interval: number of days you can choose to output the Covid-19 count, e.g. 1 would give you \n",
    "                the daily count and 7 would give you a weekly count. Default value is 1\n",
    "                \n",
    "Returns:\n",
    "    None. The output will be written to ./data/output.csv\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def aggregate(covid, metro, startdate, enddate, interval = 1):\n",
    "    metro_initial = pd.read_csv(metro)\n",
    "    metro = pd.read_csv(metro)\n",
    "    state_abbr = pd.read_csv('./data/us states abbreviations.csv')\n",
    "    metro = metro.merge(state_abbr, how ='inner', \n",
    "                         left_on = 'states_msa', \n",
    "                         right_on = 'Abbreviation')\n",
    "    metro['states_msa'] = metro['State']\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    merged = metro.merge(covid, how='inner', \n",
    "                         left_on=[\"states_msa\", \"name10_county\"], \n",
    "                         right_on=[\"state\",\"county\"])\n",
    "    merged = merged[['date', 'county', 'cases', \n",
    "                     'deaths', 'name_msa', 'states_msa_code', 'states_msa', 'states_msa_full',\n",
    "                     'geoid_msa']]  \n",
    "    merged[\"date\"] = pd.to_datetime(merged[\"date\"])\n",
    "    merged = merged[merged.date <= enddate]\n",
    "    merged = merged[merged.date >= startdate]\n",
    "    \n",
    "    #print(merged[merged['name_msa'] == 'Miami-Fort Lauderdale-West Palm Beach'])\n",
    "    #print(merged[merged['name_msa'] == 'Phoenix-Mesa-Scottsdale'])\n",
    "     \n",
    "    iterate_start = startdate\n",
    "    \n",
    "    interval_data = merged\n",
    "    output = pd.DataFrame()\n",
    "    \n",
    "    while iterate_start <= enddate:\n",
    "        iterate_end = iterate_start + timedelta(days=interval)\n",
    "        \n",
    "        #print(iterate_start, iterate_end)\n",
    "        eachInterval = interval_data[interval_data.date >= iterate_start]\n",
    "        eachInterval = eachInterval[eachInterval.date < iterate_end]\n",
    "        \n",
    "\n",
    "        eachInterval = eachInterval.groupby(['name_msa'])['cases', 'deaths'].sum()\n",
    "        eachInterval = eachInterval.merge(metro_initial, left_on='name_msa', right_on='name_msa')[['states_msa_code', 'states_msa', \n",
    "                                    'states_msa_full', \"geoid_msa\",\n",
    "                                   'name_msa', 'cases', 'deaths']].sort_values(by = 'states_msa_code')\n",
    "        eachInterval['interval_start'] = iterate_start\n",
    "        eachInterval = eachInterval.drop_duplicates(subset=['name_msa'])\n",
    "\n",
    "        output = output.append(eachInterval)\n",
    "        iterate_start = iterate_start + timedelta(days=interval)\n",
    "    \n",
    "    #print(output.head())\n",
    "    #print(output[output['name_msa'] == 'Miami-Fort Lauderdale-West Palm Beach'])\n",
    "    #print(output[output['name_msa'] == 'Phoenix-Mesa-Scottsdale'])\n",
    "    \n",
    "    output.to_csv(\"./data/output.csv\", index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "This function is for transposing the output.csv file to output the data with each\n",
    "date being a column\n",
    "\n",
    "Args:\n",
    "    input_covid: the output from aggregate function in csv format\n",
    "                \n",
    "Returns:\n",
    "    the reformatted cases and deaths data at MSA level in the US\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "def transform_MSA(input_covid):\n",
    "    input_df = pd.read_csv(input_covid)\n",
    "    geoid_msa = {}\n",
    "    MSA_all_cases = {}\n",
    "    MSA_all_deaths = {}\n",
    "    all_dates = {}\n",
    "\n",
    "    for index, row in input_df.iterrows():\n",
    "        MSA_all_cases[row['name_msa']] = []\n",
    "        MSA_all_deaths[row['name_msa']] = []\n",
    "        all_dates[row['interval_start']] = 0\n",
    "        geoid_msa[row['geoid_msa']] = 0\n",
    "    \n",
    "    for index, row in input_df.iterrows():\n",
    "        MSA_all_cases[row['name_msa']].append(row['cases'])\n",
    "        MSA_all_deaths[row['name_msa']].append(row['deaths'])\n",
    "    \n",
    "    MSA_all_cases_list = []\n",
    "    for value in MSA_all_cases.values():\n",
    "        MSA_all_cases_list.append(value)\n",
    "        \n",
    "    MSA_all_deaths_list = []\n",
    "    for value in MSA_all_deaths.values():\n",
    "        for index, v in enumerate(value):\n",
    "            value[index] = int(v)\n",
    "        #print(value)\n",
    "        MSA_all_deaths_list.append(value)\n",
    "    \n",
    "    for i in MSA_all_cases_list:\n",
    "        if (len(i) < len(all_dates)):\n",
    "            diff = len(all_dates) - len(i)\n",
    "            for j in range(diff):\n",
    "                i.insert(j, 0)\n",
    "                \n",
    "    for i in MSA_all_deaths_list:\n",
    "        if (len(i) < len(all_dates)):\n",
    "            diff = len(all_dates) - len(i)\n",
    "            for j in range(diff):\n",
    "                i.insert(j, 0)\n",
    "\n",
    "    dates = list(all_dates.keys())\n",
    "    \n",
    "\n",
    "    \n",
    "    output_cases = pd.DataFrame(MSA_all_cases_list, columns = dates)\n",
    "    output_cases.insert(0, 'geoid', list(geoid_msa.keys()))\n",
    "    output_cases.insert(1, 'name', list(MSA_all_cases.keys()))\n",
    "     \n",
    "    output_deaths = pd.DataFrame(MSA_all_deaths_list, columns = dates)\n",
    "    output_deaths.insert(0, 'geoid', list(geoid_msa.keys()))\n",
    "    output_deaths.insert(1, 'name', list(MSA_all_deaths.keys()))\n",
    "    \n",
    "\n",
    "#     output_deaths = output_deaths.astype(float)\n",
    "#     output_deaths = output_deaths.astype(int)\n",
    "#     for index, row in output_deaths.iterrows():\n",
    "#         print(row) \n",
    "    \n",
    "    \n",
    "    output_cases.to_csv(\"./data/output_cases.csv\", index = False)\n",
    "    output_deaths.to_csv(\"./data/output_deaths.csv\", index = False)\n",
    "    \n",
    "    return output_cases, output_deaths\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "This function is for transposing the global covid-19 data to output the data\n",
    "with each date being a column\n",
    "\n",
    "Args:\n",
    "    input_covid: global covid-19 data in ./data/covid_world.csv\n",
    "                \n",
    "Returns:\n",
    "    the reformatted cases and deaths data at country level\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def transform_world(input_world, begindate, enddate):\n",
    "    df = pd.read_csv(input_world)\n",
    "    \n",
    "    geoid = pd.read_csv('./data/geoid.csv')\n",
    "    df = df.merge(geoid, how='inner', \n",
    "                         left_on=['location'], \n",
    "                         right_on=['Location (Short Name)'] )\n",
    "    \n",
    "    df = df[['Geographical location identifier (decimal)', 'iso_code', 'date', 'continent', 'location', \n",
    "             'new_cases', 'new_deaths']]\n",
    "    \n",
    "    iso_country = {}\n",
    "    country_all_cases = {}\n",
    "    country_all_deaths = {}\n",
    "    all_dates = {}\n",
    "    continent = {}\n",
    "    locations = {}\n",
    "    geoid = {}\n",
    "\n",
    "    for i in range(df.shape[0]):\n",
    "        transform = df.at[i, 'date']\n",
    "        transform = transform.split('/')\n",
    "        transform = transform[0] + '-' + transform[1] + '-' + transform[2]\n",
    "        #print(transform)\n",
    "    \n",
    "    df['date'] = pd.to_datetime(df[\"date\"])\n",
    "    \n",
    "    for i in range(df.shape[0]):\n",
    "        if (df.at[i, 'date'] < begindate or df.at[i, 'date'] > enddate):\n",
    "            df = df.drop([i])\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        country_all_cases[row['iso_code']] = []\n",
    "        country_all_deaths[row['iso_code']] = []\n",
    "        all_dates[row['date']] = 0\n",
    "        iso_country[row['iso_code']] = 0\n",
    "        \n",
    "        continent[row['continent']] = 0\n",
    "        locations[row['location']] = 0\n",
    "        geoid[row['Geographical location identifier (decimal)']] = 0\n",
    "        \n",
    "    for index, row in df.iterrows():\n",
    "        country_all_cases[row['iso_code']].append(row['new_cases'])\n",
    "        country_all_deaths[row['iso_code']].append(row['new_deaths'])\n",
    "    \n",
    "    country_all_cases_list = []\n",
    "    for value in country_all_cases.values():\n",
    "        country_all_cases_list.append(value)\n",
    "        \n",
    "    country_all_deaths_list = []\n",
    "    for value in country_all_deaths.values():\n",
    "        country_all_deaths_list.append(value)\n",
    "    \n",
    "\n",
    "    dates = list(all_dates.keys())\n",
    "    \n",
    "\n",
    "    \n",
    "    output_cases = pd.DataFrame(country_all_cases_list, columns = dates)\n",
    "    output_cases.insert(0, 'geoid', list(geoid.keys()))\n",
    "    output_cases.insert(1, 'name', list(locations.keys()))\n",
    "    \n",
    "       \n",
    "    output_deaths = pd.DataFrame(country_all_deaths_list, columns = dates)\n",
    "    output_deaths.insert(0, 'geoid', list(geoid.keys()))\n",
    "    output_deaths.insert(1, 'name', list(locations.keys()))\n",
    "    \n",
    "\n",
    "    return output_cases, output_deaths\n",
    "    \n",
    "    #output_cases.to_csv(\"./data/output_cases_world.csv\", index = False)\n",
    "    #output_deaths.to_csv(\"./data/output_deaths_world.csv\", index = False)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "This function is for merging the MSA level data in the US with the country level data by calling both the transform function\n",
    "for the MSA level data and for the country level data\n",
    "\n",
    "Args:\n",
    "    begindate:\n",
    "    enddate:\n",
    "                \n",
    "Returns:\n",
    "    None. The output will be written to './data/output_cases.csv' and './data/output_deaths.csv'\n",
    "\n",
    "\"\"\"\n",
    "def merge(begindate, enddate):\n",
    "    output_cases_MSA, output_deaths_MSA = transform_MSA('./data/output.csv')\n",
    "    output_cases_world, output_deaths_world = transform_world('./data/covid_world.csv', begindate, enddate)\n",
    "    \n",
    "    for i in range(output_cases_world.shape[0]):\n",
    "        output_cases_MSA.loc[output_cases_MSA.shape[0] + i] = list(output_cases_world.loc[i])\n",
    "    \n",
    "    for i in range(output_deaths_world.shape[0]):\n",
    "        output_deaths_MSA.loc[output_deaths_MSA.shape[0] + i] = list(output_deaths_world.loc[i])\n",
    "    \n",
    "    output_cases_MSA.to_csv(\"./data/output_cases.csv\", index = False)\n",
    "    output_deaths_MSA.to_csv(\"./data/output_deaths.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "This function is for converting the output in csv format to js format \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def convert_to_js(param):\n",
    "\n",
    "    disease = param['Disease']\n",
    "    beginDate = param['begin_date']\n",
    "    endDate = param['end_date']\n",
    "    shapefile = param['shapefile']\n",
    "    \n",
    "    with open(shapefile, errors='replace') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    beginDate = str_to_date(beginDate)\n",
    "    endDate = str_to_date(endDate)\n",
    "    \n",
    "    \n",
    "    \n",
    "    df = pd.read_csv(disease)\n",
    "    \n",
    "    \n",
    " \n",
    "    columns = list(df.columns)\n",
    "    columns.pop(0)\n",
    "    columns.pop(0)\n",
    "    \n",
    "    for column in columns:\n",
    "        column_date = str_to_date(column)\n",
    "        if (column_date > endDate or column_date < beginDate):\n",
    "            df = df.drop(column, 1)\n",
    "            \n",
    "    \n",
    "    heading = list(df.columns)\n",
    "    ofile = open('./data/test.js', 'w')\n",
    "    ofile.write('var GEO_VARIABLES =\\n')\n",
    "    ofile.write('[\\n')\n",
    "    ofile.write('  '+json.dumps(heading)+',\\n')\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        values = list(row)\n",
    "        ofile.write('  '+json.dumps(values)+',\\n')\n",
    "    \n",
    "    \n",
    "    ofile.write(']\\n')\n",
    "    ofile.close()\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Helper function for converting string to datetime, string must be in the formate of \"month-date-year\", e.g. \"2-14-2020\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def str_to_date(input_string):\n",
    "    input_string = input_string.split('-')\n",
    "    \n",
    "    \n",
    "    for index in range(len(input_string)):\n",
    "        input_string[index] = int(input_string[index])\n",
    "\n",
    "    input_string = dt.datetime(input_string[0], input_string[1], input_string[2])\n",
    "    \n",
    "    return input_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inputCovid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-fa4bf771396a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0maggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputCovid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputMetro\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeginDate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendDate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m#transform_MSA('./data/output.csv')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'inputCovid' is not defined"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "import json\n",
    "import geopandas as gpd\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Change the parameters below to specify a beginning and an ending date \n",
    "    beginDate = dt.datetime(2020, 2, 14)\n",
    "    endDate = dt.datetime(2020, 3, 14)\n",
    "    interval = 1\n",
    "    inputFile = './data/Covid-19 cumulative.csv'\n",
    "    inputMetro = './data/metro_county.csv'\n",
    "    \n",
    "    \n",
    "    # dailyCount = cumulativeToDaily(inputFile)\n",
    "#     dailyCount.to_csv(\"./data/daily count.csv\", index = False)\n",
    "    \n",
    "    #inputCovid = pd.read_csv('./data/daily count.csv')\n",
    "    \n",
    "    \n",
    "    aggregate(inputCovid, inputMetro, beginDate, endDate, interval)\n",
    "    \n",
    "    #transform_MSA('./data/output.csv')\n",
    "    \n",
    "#     merge(beginDate, endDate)\n",
    "    \n",
    "#     param = {\n",
    "#         'Disease': './data/output_deaths.csv',  \n",
    "#         'begin_date': \"2020-02-22\",\n",
    "#         'end_date': \"2020-06-10\",\n",
    "#         'shapefile': \"./shp/world_region.shp\",\n",
    "#     }\n",
    "    \n",
    "#     convert_to_js(param)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
