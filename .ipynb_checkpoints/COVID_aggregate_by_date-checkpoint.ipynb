{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from datetime import timedelta\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "This function is for converting cumulative count to daily count and write to the data folder\n",
    "\n",
    "Args:\n",
    "    inputFile: the cumulative count at county level collected from New York Times\n",
    "                the path for it is at './data/Covid-19 cumulative.csv'\n",
    "                \n",
    "Returns:\n",
    "    the daily count in dataframe format\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def cumulativeToDaily(inputFile):\n",
    "    data = pd.read_csv(inputFile)\n",
    "    copy = pd.read_csv(inputFile)\n",
    "    data = data.sort_values(by=['county', 'state'])\n",
    "    copy = copy.sort_values(by=['county', 'state'])\n",
    "    data.to_csv(\"./data/daily count.csv\", index = False)\n",
    "    data = pd.read_csv(\"./data/daily count.csv\")\n",
    "    copy.to_csv(\"./data/daily count_copy.csv\", index = False)\n",
    "    copy = pd.read_csv(\"./data/daily count_copy.csv\")\n",
    "    i = 1\n",
    "    data['fips'] = data['fips'].fillna(-1)\n",
    "    while i < len(data.index):\n",
    "        if data.at[i, 'county'] == data.at[i - 1, 'county'] and data.at[i, 'state'] == data.at[i - 1, 'state']:\n",
    "            if (data.at[i, 'cases'] < copy.at[i - 1, 'cases']):\n",
    "                data.at[i, 'cases'] = copy.at[i - 1, 'cases']\n",
    "            if (data.at[i, 'deaths'] < copy.at[i - 1, 'deaths']):\n",
    "                data.at[i, 'deaths'] = copy.at[i - 1, 'deaths']\n",
    "            data.at[i, 'cases'] = data.at[i, 'cases'] - copy.at[i - 1, 'cases']\n",
    "            data.at[i, 'deaths'] = data.at[i, 'deaths'] - copy.at[i - 1, 'deaths']\n",
    "        i += 1\n",
    "    data = data.astype({'fips': int})\n",
    "    data[\"date\"] = pd.to_datetime(data[\"date\"])\n",
    "    data = data.sort_values(by = ['date'])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "This function is for aggregating Covid-19 count from county level to MSA level\n",
    "\n",
    "Args:\n",
    "    covid: the daily count in csv format\n",
    "    metro: a reference table in csv format for showing all the MSAs and the counties included in them\n",
    "    interval: number of days you can choose to output the Covid-19 count, e.g. 1 would give you \n",
    "                the daily count and 7 would give you a weekly count. Default value is 1\n",
    "                \n",
    "Returns:\n",
    "    None. The output will be written to ./data/output.csv\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def aggregate(covid, metro, startdate, enddate, interval = 1):\n",
    "    metro_initial = pd.read_csv(metro)\n",
    "    metro = pd.read_csv(metro)\n",
    "    state_abbr = pd.read_csv('./data/us states abbreviations.csv')\n",
    "    metro = metro.merge(state_abbr, how ='inner', \n",
    "                         left_on = 'states_msa', \n",
    "                         right_on = 'Abbreviation')\n",
    "    metro['states_msa'] = metro['State']\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    merged = metro.merge(covid, how='inner', \n",
    "                         left_on=[\"states_msa\", \"name10_county\"], \n",
    "                         right_on=[\"state\",\"county\"])\n",
    "    merged = merged[['date', 'county', 'cases', \n",
    "                     'deaths', 'name_msa', 'states_msa_code', 'states_msa', 'states_msa_full',\n",
    "                     'geoid_msa']]  \n",
    "    merged[\"date\"] = pd.to_datetime(merged[\"date\"])\n",
    "    merged = merged[merged.date <= enddate]\n",
    "    merged = merged[merged.date >= startdate]\n",
    "     \n",
    "    iterate_start = startdate\n",
    "    \n",
    "    interval_data = merged\n",
    "    output = pd.DataFrame()\n",
    "    \n",
    "    while iterate_start <= enddate:\n",
    "        iterate_end = iterate_start + timedelta(days=interval)\n",
    "        \n",
    "        eachInterval = interval_data[interval_data.date >= iterate_start]\n",
    "        eachInterval = eachInterval[eachInterval.date <= iterate_end]\n",
    "        \n",
    "\n",
    "        eachInterval = eachInterval.groupby(['name_msa'])['cases', 'deaths'].sum()\n",
    "        eachInterval = eachInterval.merge(metro_initial, left_on='name_msa', right_on='name_msa')[['states_msa_code', 'states_msa', \n",
    "                                    'states_msa_full', \"geoid_msa\",\n",
    "                                   'name_msa', 'cases', 'deaths']].sort_values(by = 'states_msa_code')\n",
    "        eachInterval['interval_start'] = iterate_start\n",
    "        eachInterval = eachInterval.drop_duplicates(subset=['name_msa'])\n",
    "\n",
    "        output = output.append(eachInterval)\n",
    "        iterate_start = iterate_start + timedelta(days=interval)\n",
    "    \n",
    "    \n",
    "    output.to_csv(\"./data/output.csv\", index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "This function is for transposing the output.csv file to output the data with each\n",
    "date being a column\n",
    "\n",
    "Args:\n",
    "    input_covid: the output from aggregate function in csv format\n",
    "                \n",
    "Returns:\n",
    "    None. The output will be written to './data/output_cases.csv' and './data/output_deaths.csv'\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "def transform(input_covid):\n",
    "    input_df = pd.read_csv(input_covid)\n",
    "    geoid_msa = {}\n",
    "    MSA_all_cases = {}\n",
    "    MSA_all_deaths = {}\n",
    "    all_dates = {}\n",
    "\n",
    "    for index, row in input_df.iterrows():\n",
    "        MSA_all_cases[row['name_msa']] = []\n",
    "        MSA_all_deaths[row['name_msa']] = []\n",
    "        all_dates[row['interval_start']] = 0\n",
    "        geoid_msa[row['geoid_msa']] = 0\n",
    "        \n",
    "    for index, row in input_df.iterrows():\n",
    "        MSA_all_cases[row['name_msa']].append(row['cases'])\n",
    "        MSA_all_deaths[row['name_msa']].append(row['deaths'])\n",
    "    \n",
    "    MSA_all_cases_list = []\n",
    "    for value in MSA_all_cases.values():\n",
    "        MSA_all_cases_list.append(value)\n",
    "        \n",
    "    MSA_all_deaths_list = []\n",
    "    for value in MSA_all_deaths.values():\n",
    "        MSA_all_deaths_list.append(value)\n",
    "    \n",
    "    for i in MSA_all_cases_list:\n",
    "        if (len(i) < len(all_dates)):\n",
    "            diff = len(all_dates) - len(i)\n",
    "            for j in range(diff):\n",
    "                i.insert(j, 0)\n",
    "                \n",
    "    for i in MSA_all_deaths_list:\n",
    "        if (len(i) < len(all_dates)):\n",
    "            diff = len(all_dates) - len(i)\n",
    "            for j in range(diff):\n",
    "                i.insert(j, 0)\n",
    "\n",
    "    dates = list(all_dates.keys())\n",
    "    \n",
    "\n",
    "    \n",
    "    output_cases = pd.DataFrame(MSA_all_cases_list, columns = dates)\n",
    "    output_cases.insert(0, 'name_msa', list(MSA_all_cases.keys()))\n",
    "    output_cases.insert(1, 'geoid_msa', list(geoid_msa.keys()))\n",
    "    \n",
    "    output_deaths = pd.DataFrame(MSA_all_deaths_list, columns = dates)\n",
    "    output_deaths.insert(0, 'name_msa', list(MSA_all_deaths.keys()))\n",
    "    output_deaths.insert(1, 'geoid_msa', list(geoid_msa.keys()))\n",
    "    \n",
    "    output_cases.to_csv(\"./data/output_cases.csv\", index = False)\n",
    "    output_deaths.to_csv(\"./data/output_deaths.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikeq\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:34: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Change the parameters below to specify a beginning and an ending date \n",
    "    beginDate = dt.datetime(2020, 2, 14)\n",
    "    endDate = dt.datetime(2020, 6, 11)\n",
    "    interval = 1\n",
    "    inputFile = './data/Covid-19 cumulative.csv'\n",
    "    inputMetro = './data/metro_county.csv'\n",
    "    \n",
    "    \n",
    "    dailyCount = cumulativeToDaily(inputFile)\n",
    "    dailyCount.to_csv(\"./data/daily count.csv\", index = False)\n",
    "    inputCovid = pd.read_csv(\"./data/daily count.csv\")\n",
    "    \n",
    "    aggregate(inputCovid, inputMetro, beginDate, endDate, interval)\n",
    "    \n",
    "    transform('./data/output.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
