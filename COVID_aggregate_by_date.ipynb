{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "This function is for converting cumulative count to daily count and write to the data folder\n",
    "\n",
    "Args:\n",
    "    inputFile: the cumulative count at county level collected from New York Times\n",
    "                the path for it is at './data/Covid-19 cumulative.csv'\n",
    "                \n",
    "Returns:\n",
    "    the daily count in dataframe format\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def cumulativeToDaily(inputFile):\n",
    "    data = pd.read_csv(inputFile)\n",
    "    copy = pd.read_csv(inputFile)\n",
    "    data = data.sort_values(by=['county', 'state'])\n",
    "    copy = copy.sort_values(by=['county', 'state'])\n",
    "    data.to_csv(\"./data/daily count.csv\", index = False)\n",
    "    data = pd.read_csv(\"./data/daily count.csv\")\n",
    "    copy.to_csv(\"./data/daily count_copy.csv\", index = False)\n",
    "    copy = pd.read_csv(\"./data/daily count_copy.csv\")\n",
    "    i = 1\n",
    "    data['fips'] = data['fips'].fillna(-1)\n",
    "    while i < len(data.index):\n",
    "        if data.at[i, 'county'] == data.at[i - 1, 'county'] and data.at[i, 'state'] == data.at[i - 1, 'state']:\n",
    "            if (data.at[i, 'cases'] < copy.at[i - 1, 'cases']):\n",
    "                data.at[i, 'cases'] = copy.at[i - 1, 'cases']\n",
    "            if (data.at[i, 'deaths'] < copy.at[i - 1, 'deaths']):\n",
    "                data.at[i, 'deaths'] = copy.at[i - 1, 'deaths']\n",
    "            data.at[i, 'cases'] = data.at[i, 'cases'] - copy.at[i - 1, 'cases']\n",
    "            data.at[i, 'deaths'] = data.at[i, 'deaths'] - copy.at[i - 1, 'deaths']\n",
    "        i += 1\n",
    "    data = data.astype({'fips': int})\n",
    "    data[\"date\"] = pd.to_datetime(data[\"date\"])\n",
    "    data = data.sort_values(by = ['date'])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "This function is for aggregating Covid-19 count from county level to MSA level\n",
    "\n",
    "Args:\n",
    "    covid: the daily count in csv format\n",
    "    metro: a reference table in csv format for showing all the MSAs and the counties included in them\n",
    "    interval: number of days you can choose to output the Covid-19 count, e.g. 1 would give you \n",
    "                the daily count and 7 would give you a weekly count. Default value is 1\n",
    "                \n",
    "Returns:\n",
    "    None. The output will be written to ./data/output.csv\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def aggregate(covid, metro, startdate, enddate, interval = 1):\n",
    "    metro_initial = pd.read_csv(metro)\n",
    "    metro = pd.read_csv(metro)\n",
    "    state_abbr = pd.read_csv('./data/us states abbreviations.csv')\n",
    "    metro = metro.merge(state_abbr, how ='inner', \n",
    "                         left_on = 'states_msa', \n",
    "                         right_on = 'Abbreviation')\n",
    "    metro['states_msa'] = metro['State']\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    merged = metro.merge(covid, how='inner', \n",
    "                         left_on=[\"states_msa\", \"name10_county\"], \n",
    "                         right_on=[\"state\",\"county\"])\n",
    "    merged = merged[['date', 'county', 'cases', \n",
    "                     'deaths', 'name_msa', 'states_msa_code', 'states_msa', 'states_msa_full',\n",
    "                     'geoid_msa']]  \n",
    "    merged[\"date\"] = pd.to_datetime(merged[\"date\"])\n",
    "    merged = merged[merged.date <= enddate]\n",
    "    merged = merged[merged.date >= startdate]\n",
    "     \n",
    "    iterate_start = startdate\n",
    "    \n",
    "    interval_data = merged\n",
    "    output = pd.DataFrame()\n",
    "    \n",
    "    while iterate_start <= enddate:\n",
    "        iterate_end = iterate_start + timedelta(days=interval)\n",
    "        \n",
    "        eachInterval = interval_data[interval_data.date >= iterate_start]\n",
    "        eachInterval = eachInterval[eachInterval.date <= iterate_end]\n",
    "        \n",
    "\n",
    "        eachInterval = eachInterval.groupby(['name_msa'])['cases', 'deaths'].sum()\n",
    "        eachInterval = eachInterval.merge(metro_initial, left_on='name_msa', right_on='name_msa')[['states_msa_code', 'states_msa', \n",
    "                                    'states_msa_full', \"geoid_msa\",\n",
    "                                   'name_msa', 'cases', 'deaths']].sort_values(by = 'states_msa_code')\n",
    "        eachInterval['interval_start'] = iterate_start\n",
    "        eachInterval = eachInterval.drop_duplicates(subset=['name_msa'])\n",
    "\n",
    "        output = output.append(eachInterval)\n",
    "        iterate_start = iterate_start + timedelta(days=interval)\n",
    "    \n",
    "    \n",
    "    output.to_csv(\"./data/output.csv\", index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "This function is for transposing the output.csv file to output the data with each\n",
    "date being a column\n",
    "\n",
    "Args:\n",
    "    input_covid: the output from aggregate function in csv format\n",
    "                \n",
    "Returns:\n",
    "    None. The output will be written to './data/output_cases.csv' and './data/output_deaths.csv'\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "def transform(input_covid):\n",
    "    input_df = pd.read_csv(input_covid)\n",
    "    geoid_msa = {}\n",
    "    MSA_all_cases = {}\n",
    "    MSA_all_deaths = {}\n",
    "    all_dates = {}\n",
    "\n",
    "    for index, row in input_df.iterrows():\n",
    "        MSA_all_cases[row['name_msa']] = []\n",
    "        MSA_all_deaths[row['name_msa']] = []\n",
    "        all_dates[row['interval_start']] = 0\n",
    "        geoid_msa[row['geoid_msa']] = 0\n",
    "        \n",
    "    for index, row in input_df.iterrows():\n",
    "        MSA_all_cases[row['name_msa']].append(row['cases'])\n",
    "        MSA_all_deaths[row['name_msa']].append(row['deaths'])\n",
    "    \n",
    "    MSA_all_cases_list = []\n",
    "    for value in MSA_all_cases.values():\n",
    "        MSA_all_cases_list.append(value)\n",
    "        \n",
    "    MSA_all_deaths_list = []\n",
    "    for value in MSA_all_deaths.values():\n",
    "        MSA_all_deaths_list.append(value)\n",
    "    \n",
    "    for i in MSA_all_cases_list:\n",
    "        if (len(i) < len(all_dates)):\n",
    "            diff = len(all_dates) - len(i)\n",
    "            for j in range(diff):\n",
    "                i.insert(j, 0)\n",
    "                \n",
    "    for i in MSA_all_deaths_list:\n",
    "        if (len(i) < len(all_dates)):\n",
    "            diff = len(all_dates) - len(i)\n",
    "            for j in range(diff):\n",
    "                i.insert(j, 0)\n",
    "\n",
    "    dates = list(all_dates.keys())\n",
    "    \n",
    "\n",
    "    \n",
    "    output_cases = pd.DataFrame(MSA_all_cases_list, columns = dates)\n",
    "    output_cases.insert(0, 'name', list(MSA_all_cases.keys()))\n",
    "    output_cases.insert(1, 'geoid', list(geoid_msa.keys()))\n",
    "    \n",
    "    output_deaths = pd.DataFrame(MSA_all_deaths_list, columns = dates)\n",
    "    output_deaths.insert(0, 'name', list(MSA_all_deaths.keys()))\n",
    "    output_deaths.insert(1, 'geoid', list(geoid_msa.keys()))\n",
    "  \n",
    "    return output_cases, output_deaths\n",
    "\n",
    "#     output_cases.to_csv(\"./data/output_cases.csv\", index = False)\n",
    "#     output_deaths.to_csv(\"./data/output_deaths.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "This function is for transposing the global covid-19 data to output the data\n",
    "with each date being a column\n",
    "\n",
    "Args:\n",
    "    input_covid: global covid-19 data in ./data/covid_world.csv\n",
    "                \n",
    "Returns:\n",
    "    None. The output will be merged with the US data in './data/output_cases.csv' and './data/output_deaths.csv'\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def transform_world(input_world, begindate, enddate):\n",
    "    df = pd.read_csv(input_world)\n",
    "    \n",
    "    geoid = pd.read_csv('./data/geoid.csv')\n",
    "    df = df.merge(geoid, how='inner', \n",
    "                         left_on=['location'], \n",
    "                         right_on=['Location (Short Name)'] )\n",
    "    \n",
    "    df = df[['Geographical location identifier (decimal)', 'iso_code', 'date', 'continent', 'location', \n",
    "             'new_cases', 'new_deaths']]\n",
    "    \n",
    "    iso_country = {}\n",
    "    country_all_cases = {}\n",
    "    country_all_deaths = {}\n",
    "    all_dates = {}\n",
    "    continent = {}\n",
    "    locations = {}\n",
    "    geoid = {}\n",
    "\n",
    "    for i in range(df.shape[0]):\n",
    "        transform = df.at[i, 'date']\n",
    "        transform = transform.split('/')\n",
    "        transform = transform[0] + '-' + transform[1] + '-' + transform[2]\n",
    "        #print(transform)\n",
    "    \n",
    "    df['date'] = pd.to_datetime(df[\"date\"])\n",
    "    \n",
    "    for i in range(df.shape[0]):\n",
    "        if (df.at[i, 'date'] < begindate or df.at[i, 'date'] > enddate):\n",
    "            df = df.drop([i])\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        country_all_cases[row['iso_code']] = []\n",
    "        country_all_deaths[row['iso_code']] = []\n",
    "        all_dates[row['date']] = 0\n",
    "        iso_country[row['iso_code']] = 0\n",
    "        \n",
    "        continent[row['continent']] = 0\n",
    "        locations[row['location']] = 0\n",
    "        geoid[row['Geographical location identifier (decimal)']] = 0\n",
    "        \n",
    "    for index, row in df.iterrows():\n",
    "        country_all_cases[row['iso_code']].append(row['new_cases'])\n",
    "        country_all_deaths[row['iso_code']].append(row['new_deaths'])\n",
    "    \n",
    "    country_all_cases_list = []\n",
    "    for value in country_all_cases.values():\n",
    "        country_all_cases_list.append(value)\n",
    "        \n",
    "    country_all_deaths_list = []\n",
    "    for value in country_all_deaths.values():\n",
    "        country_all_deaths_list.append(value)\n",
    "    \n",
    "\n",
    "    dates = list(all_dates.keys())\n",
    "    \n",
    "\n",
    "    \n",
    "    output_cases = pd.DataFrame(country_all_cases_list, columns = dates)\n",
    "    output_cases.insert(0, 'name', list(locations.keys()))\n",
    "    output_cases.insert(1, 'geoid', list(geoid.keys()))\n",
    "   \n",
    "    \n",
    "    output_deaths = pd.DataFrame(country_all_deaths_list, columns = dates)\n",
    "    output_deaths.insert(0, 'name', list(locations.keys()))\n",
    "    output_deaths.insert(1, 'geoid', list(geoid.keys()))\n",
    "    \n",
    "\n",
    "    \n",
    "    return output_cases, output_deaths\n",
    "    \n",
    "    #output_cases.to_csv(\"./data/output_cases_world.csv\", index = False)\n",
    "    #output_deaths.to_csv(\"./data/output_deaths_world.csv\", index = False)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(begindate, enddate):\n",
    "    output_cases_MSA, output_deaths_MSA = transform('./data/output.csv')\n",
    "    output_cases_world, output_deaths_world = transform_world('./data/covid_world.csv', begindate, enddate)\n",
    "    \n",
    "    for i in range(output_cases_world.shape[0]):\n",
    "        output_cases_MSA.loc[output_cases_MSA.shape[0] + i] = list(output_cases_world.loc[i])\n",
    "    \n",
    "    for i in range(output_deaths_world.shape[0]):\n",
    "        output_deaths_MSA.loc[output_deaths_MSA.shape[0] + i] = list(output_deaths_world.loc[i])\n",
    "    \n",
    "    output_cases_MSA.to_csv(\"./data/output_cases.csv\", index = False)\n",
    "    output_deaths_MSA.to_csv(\"./data/output_deaths.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Change the parameters below to specify a beginning and an ending date \n",
    "    beginDate = dt.datetime(2020, 2, 14)\n",
    "    endDate = dt.datetime(2020, 6, 11)\n",
    "    interval = 1\n",
    "    inputFile = './data/Covid-19 cumulative.csv'\n",
    "    inputMetro = './data/metro_county.csv'\n",
    "    \n",
    "    \n",
    "#     dailyCount = cumulativeToDaily(inputFile)\n",
    "#     dailyCount.to_csv(\"./data/daily count.csv\", index = False)\n",
    "#     inputCovid = pd.read_csv(\"./data/daily count.csv\")\n",
    "    \n",
    "#     aggregate(inputCovid, inputMetro, beginDate, endDate, interval)\n",
    "    \n",
    "\n",
    "    merge(beginDate, endDate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
